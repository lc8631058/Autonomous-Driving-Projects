{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from keras.layers import pooling\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Flatten, Dense, Lambda, Activation\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Cropping2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "with open('./data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "#         print(line[0])\n",
    "        lines.append(line)\n",
    "    lines = lines[1:]\n",
    "\n",
    "# path = './data/'\n",
    "# get_None_idx = []\n",
    "# for idx, line in enumerate(lines):\n",
    "#     line[1] = line[1][1:]\n",
    "#     line[2] = line[2][1:]\n",
    "#     if cv2.imread(path + line[0]) is None:\n",
    "#         get_None_idx.append(idx)\n",
    "    \n",
    "#     if cv2.imread(path + line[1]) is None:\n",
    "#         get_None_idx.append(idx)\n",
    "        \n",
    "#     if cv2.imread(path + line[2]) is None:\n",
    "#         get_None_idx.append(idx)\n",
    "    \n",
    "# images = []\n",
    "# measurments = []\n",
    "# for line in lines:\n",
    "#     # Create train_X\n",
    "#     # read in images from center, left and right cameras    \n",
    "#     image_center = cv2.imread(path + line[0]) # load the center_image\n",
    "#     image_left = cv2.imread(path + line[1]) # load the left_image\n",
    "#     image_right = cv2.imread(path + line[2]) # load the right_image\n",
    "    \n",
    "#     # append every image to images list\n",
    "#     images.extend((image_center, image_left, image_right)) \n",
    "    \n",
    "#     # Create train_Y\n",
    "#     steering_center = float(line[3])# steering measurment\n",
    "#     # create adjusted steering measurements for the side camera images\n",
    "#     correction = 0.2 # this is a parameter to tune\n",
    "#     steering_left = steering_center + correction\n",
    "#     steering_right = steering_center - correction\n",
    "    \n",
    "#     measurments.extend((steering_center, steering_left, steering_right))\n",
    "    \n",
    "# images = np.array(images)\n",
    "# measurments = np.array(measurments)\n",
    "\n",
    "# # Data augumentation: flip image in order to let it includes both clockwise and counter-clockwise images\n",
    "# flip_images = []\n",
    "# measurments_flipped = []\n",
    "# for image, measurement in zip(images, measurements):\n",
    "#     flip_images.append(np.fliplr(image))\n",
    "#     measurments_flipped.append(-measurement)\n",
    "# flip_images = np.array(flip_images)\n",
    "# measurments_flipped = np.array(measurments_flipped)\n",
    "\n",
    "# train_X = np.array(np.concatenate([images, flip_images], axis=0))\n",
    "# train_Y = np.array(np.concatenate([measurments, measurments_flipped], axis=0))\n",
    "\n",
    "# # train, validation split\n",
    "# train_samples, validation_samples = train_test_split(samples, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# angle = []\n",
    "for ii in lines:\n",
    "    angle.append(float(ii[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'angle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e9bcfc4485ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcount_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mangle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mcount_0\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcount_0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'angle' is not defined"
     ]
    }
   ],
   "source": [
    "count_0 = 0\n",
    "for i in angle:\n",
    "    if i == 0.0:\n",
    "        count_0 += 1 \n",
    "count_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histgram\n",
    "bins = np.arange(-0.5, 0.5, 0.01)\n",
    "\n",
    "plt.hist(angle, bins=bins, alpha=0.3, label='angles')\n",
    "# plt.hist(np.concatenate([L2_label_1_full,L2_label_1_test_full],axis=0), bins=bins, alpha=0.3, label='label_1')\n",
    "# plt.hist(y_test, bins=bins, alpha=0.3, label='y_test')\n",
    "plt.title('Distribution of different steering angles')\n",
    "plt.ylabel('numbers')\n",
    "plt.xlabel('Angles')\n",
    "plt.legend(loc='upper right')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# center_with_zero_list = []\n",
    "# for zero_idx in train_zero_angle_idx:\n",
    "#     center_with_zero_list.append([train_samples[zero_idx][0], 0.0, 'C'])\n",
    "    \n",
    "#     # pick up the center and side images path that with non-zero angles\n",
    "# center_with_non_zero_list = []\n",
    "# left_with_non_zero_list = []\n",
    "# right_with_non_zero_list = []\n",
    "\n",
    "# for non_zero_idx in train_non_zero_angle_idx:\n",
    "#         # create adjusted steering measurements for the side camera images\n",
    "#     center_with_non_zero_list.append([train_samples[non_zero_idx][0], train_samples[non_zero_idx][3], 'C'])\n",
    "#     left_with_non_zero_list.append([train_samples[non_zero_idx][1], float(train_samples[non_zero_idx][3]) + 0.2, 'L'])\n",
    "#     right_with_non_zero_list.append([train_samples[non_zero_idx][2], float(train_samples[non_zero_idx][3]) - 0.2, 'R'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_with_zero_list = []\n",
    "for zero_idx in zero_angle_idx:\n",
    "    center_with_zero_list.append([lines[zero_idx][0], 0.0, 'C'])\n",
    "    \n",
    "    # pick up the center and side images path that with non-zero angles\n",
    "center_with_non_zero_list = []\n",
    "left_with_non_zero_list = []\n",
    "right_with_non_zero_list = []\n",
    "\n",
    "for non_zero_idx in non_zero_angle_idx:\n",
    "        # create adjusted steering measurements for the side camera images\n",
    "    center_with_non_zero_list.append([lines[non_zero_idx][0], lines[non_zero_idx][3], 'C'])\n",
    "    left_with_non_zero_list.append([lines[non_zero_idx][1], float(lines[non_zero_idx][3]) + 0.2, 'L'])\n",
    "    right_with_non_zero_list.append([lines[non_zero_idx][2], float(lines[non_zero_idx][3]) - 0.2, 'R'])\n",
    "    \n",
    "samples = np.concatenate([np.array(center_with_zero_list), np.array(center_with_non_zero_list),\n",
    "                              np.array(left_with_non_zero_list), np.array(right_with_non_zero_list)], axis=0)\n",
    "    \n",
    "num_samples = len(samples)\n",
    "while 1: # Loop forever so the generator never terminates\n",
    "    samples = shuffle(samples)\n",
    "    \n",
    "    for start_point in range(0, num_samples, batch_size):\n",
    "        batch_samples = samples[start_point : start_point + batch_size]\n",
    "            \n",
    "        image_center_list = []\n",
    "        image_center_angle = []\n",
    "        image_side_list = []\n",
    "        image_side_angle = []\n",
    "            \n",
    "        for sample in batch_samples:\n",
    "            path = './data/'\n",
    "            # Create train_X\n",
    "            # read in images from center, left and right cameras    \n",
    "            if sample[2] == 'C':\n",
    "                image_center = cv2.imread(path + sample[0]) # load the center_image\n",
    "                image_center_list.append(image_center) \n",
    "                image_center_angle.append(float(sample[1]))\n",
    "                    \n",
    "            if sample[2] == 'L' or sample[2] == 'R':\n",
    "                image_side = cv2.imread(path + sample[0]) # load the left_image\n",
    "                image_side_list.append(image_side) \n",
    "                image_side_angle.append(float(sample[1]))\n",
    "\n",
    "        image_center_list = np.array(image_center_list)\n",
    "        image_center_angle = np.array(image_center_angle)\n",
    "        image_side_list = np.array(image_side_list)\n",
    "        image_side_angle = np.array(image_side_angle)\n",
    "#         print(image_side_list)\n",
    "            # Data augumentation: flip image in order to let it includes both clockwise and counter-clockwise images\n",
    "            \n",
    "            # only flip side-images:\n",
    "        if len(image_side_list) != 0:\n",
    "            images_flipped = []\n",
    "            angles_flipped = []\n",
    "            for image, angle in zip(image_side_list, image_side_angle):\n",
    "                images_flipped.append(cv2.flip(image, 1))\n",
    "                angles_flipped.append(angle*-1.0)\n",
    "            images_flipped = np.array(images_flipped)\n",
    "            angles_flipped = np.array(angles_flipped)\n",
    "            \n",
    "#         print(image_center_list.shape, image_side_list.shape, images_flipped.shape)\n",
    "    \n",
    "        train_X = np.array(np.concatenate([image_center_list, image_side_list, images_flipped], axis=0))\n",
    "        train_Y = np.array(np.concatenate([image_center_angle, image_side_angle, angles_flipped], axis=0))\n",
    "        train_X, train_Y = sklearn.utils.shuffle(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [cv2.flip](https://docs.opencv.org/2.4/modules/core/doc/operations_on_arrays.html?highlight=cv2.flip#cv2.flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(lines, zero_angle_idx, non_zero_angle_idx, batch_size=50, correc=0.3):\n",
    "    \n",
    "    '''\n",
    "    samples: \n",
    "    correc: parameter to control the deviation of left and right steering angles\n",
    "    batch_size: you know what is that\n",
    "    '''\n",
    "    # pick up the center images path that with zero angles\n",
    "    center_with_zero_list = []\n",
    "    for zero_idx in zero_angle_idx:\n",
    "        center_with_zero_list.append([lines[zero_idx][0], 0.0, 'C'])\n",
    "    \n",
    "    # pick up the center and side images path that with non-zero angles\n",
    "    center_with_non_zero_list = []\n",
    "    left_with_non_zero_list = []\n",
    "    right_with_non_zero_list = []\n",
    "\n",
    "    for non_zero_idx in non_zero_angle_idx:\n",
    "        # create adjusted steering measurements for the side camera images\n",
    "        center_with_non_zero_list.append([lines[non_zero_idx][0], lines[non_zero_idx][3], 'C'])\n",
    "        left_with_non_zero_list.append([lines[non_zero_idx][1], float(lines[non_zero_idx][3]) + correc, 'L'])\n",
    "        right_with_non_zero_list.append([lines[non_zero_idx][2], float(lines[non_zero_idx][3]) - correc, 'R'])\n",
    "    \n",
    "    samples = np.concatenate([np.array(center_with_zero_list), np.array(center_with_non_zero_list),\n",
    "                              np.array(left_with_non_zero_list), np.array(right_with_non_zero_list)], axis=0)\n",
    "    \n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        samples = shuffle(samples)\n",
    "    \n",
    "        for start_point in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[start_point : start_point + batch_size]\n",
    "            \n",
    "            image_center_list = []\n",
    "            image_center_angle = []\n",
    "            image_side_list = []\n",
    "            image_side_angle = []\n",
    "            \n",
    "            for sample in batch_samples:\n",
    "                path = './data/'\n",
    "            # Create train_X\n",
    "            # read in images from center, left and right cameras    \n",
    "                if sample[2] == 'C':\n",
    "                    image_center = cv2.imread(path + sample[0]) # load the center_image\n",
    "                    image_center_list.append(image_center) \n",
    "                    image_center_angle.append(float(sample[1]))\n",
    "                    \n",
    "                if sample[2] == 'L' or sample[2] == 'R':\n",
    "                    image_side = cv2.imread(path + sample[0]) # load the left_image\n",
    "                    image_side_list.append(image_side) \n",
    "                    image_side_angle.append(float(sample[1]))\n",
    "\n",
    "            image_center_list = np.array(image_center_list)\n",
    "            image_center_angle = np.array(image_center_angle)\n",
    "            image_side_list = np.array(image_side_list)\n",
    "            image_side_angle = np.array(image_side_angle)\n",
    "\n",
    "            # Data augumentation: flip image in order to let it includes both clockwise and counter-clockwise images\n",
    "            \n",
    "            # only flip side-images:\n",
    "            images_flipped = []\n",
    "            angles_flipped = []\n",
    "            for image, angle in zip(image_side_list, image_side_angle):\n",
    "                images_flipped.append(cv2.flip(image, 1))\n",
    "                angles_flipped.append(angle*-1.0)\n",
    "            images_flipped = np.array(images_flipped)\n",
    "            angles_flipped = np.array(angles_flipped)\n",
    "            \n",
    "            train_X = np.array(np.concatenate([image_center_list, image_side_list, images_flipped], axis=0))\n",
    "            train_Y = np.array(np.concatenate([image_center_angle, image_side_angle, angles_flipped], axis=0))\n",
    "            train_X, train_Y = sklearn.utils.shuffle(train_X, train_Y)\n",
    "        \n",
    "            yield train_X, train_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To build the Network Archtecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index(lines):\n",
    "    '''\n",
    "    find out the index of the lines which have zero angles and non-zero angles\n",
    "    '''\n",
    "    zero_angle_idx = []\n",
    "    non_zero_angle_idx = []\n",
    "    for idx, line in enumerate(lines):\n",
    "        if line[3] == '0':\n",
    "            zero_angle_idx.append(idx)\n",
    "        else:\n",
    "            non_zero_angle_idx.append(idx)\n",
    "            \n",
    "    return zero_angle_idx, non_zero_angle_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, validation split\n",
    "# actually we split the path but not total data, the data will be read by generator\n",
    "train_samples, validation_samples = train_test_split(lines, test_size=0.2)\n",
    "\n",
    "# cut angle zero data, find out the index of zero-angle data and non-zero-angle data\n",
    "# pick up the data with zero steer angles\n",
    "train_zero_angle_idx, train_non_zero_angle_idx = find_index(train_samples)\n",
    "valid_zero_angle_idx, valid_non_zero_angle_idx = find_index(validation_samples)\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "correct = 0.25\n",
    "batch_size = 40\n",
    "\n",
    "train_generator = data_generator(train_samples, train_zero_angle_idx, train_non_zero_angle_idx, batch_size=batch_size, correc=correct)\n",
    "validation_generator = data_generator(validation_samples, valid_zero_angle_idx, valid_non_zero_angle_idx, batch_size=batch_size, correc=correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/160\n",
      "6409/6428 [============================>.] - ETA: 1s - loss: 4.5104"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\keras\\engine\\training.py:1569: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6469/6428 [==============================] - 490s - loss: 4.4932 - val_loss: 0.0763\n",
      "Epoch 2/160\n",
      "6468/6428 [==============================] - 485s - loss: 2.7904 - val_loss: 0.0647\n",
      "Epoch 3/160\n",
      "6482/6428 [==============================] - 482s - loss: 2.1518 - val_loss: 0.0578\n",
      "Epoch 4/160\n",
      "6430/6428 [==============================] - 476s - loss: 1.5566 - val_loss: 0.0597\n",
      "Epoch 5/160\n",
      "6466/6428 [==============================] - 477s - loss: 1.2489 - val_loss: 0.0561\n",
      "Epoch 6/160\n",
      "6479/6428 [==============================] - 481s - loss: 1.0634 - val_loss: 0.0539\n",
      "Epoch 7/160\n",
      "6433/6428 [==============================] - 474s - loss: 0.8548 - val_loss: 0.0507\n",
      "Epoch 8/160\n",
      "6436/6428 [==============================] - 474s - loss: 0.6992 - val_loss: 0.0477\n",
      "Epoch 9/160\n",
      "6440/6428 [==============================] - 473s - loss: 0.6304 - val_loss: 0.0503\n",
      "Epoch 10/160\n",
      "6456/6428 [==============================] - 475s - loss: 0.5360 - val_loss: 0.0515\n",
      "Epoch 11/160\n",
      "6465/6428 [==============================] - 479s - loss: 0.4837 - val_loss: 0.0537\n",
      "Epoch 12/160\n",
      "6480/6428 [==============================] - 481s - loss: 0.3986 - val_loss: 0.0501\n",
      "Epoch 13/160\n",
      "6441/6428 [==============================] - 476s - loss: 0.3541 - val_loss: 0.0526\n",
      "Epoch 14/160\n",
      "6440/6428 [==============================] - 474s - loss: 0.2872 - val_loss: 0.0529\n",
      "Epoch 15/160\n",
      "6476/6428 [==============================] - 474s - loss: 0.2632 - val_loss: 0.0558\n",
      "Epoch 16/160\n",
      "6439/6428 [==============================] - 476s - loss: 0.2350 - val_loss: 0.0556\n",
      "Epoch 17/160\n",
      "6470/6428 [==============================] - 478s - loss: 0.2212 - val_loss: 0.0555\n",
      "Epoch 18/160\n",
      "6435/6428 [==============================] - 475s - loss: 0.2036 - val_loss: 0.0564\n",
      "Epoch 19/160\n",
      "6461/6428 [==============================] - 475s - loss: 0.1675 - val_loss: 0.0528\n",
      "Epoch 20/160\n",
      "6475/6428 [==============================] - 481s - loss: 0.1591 - val_loss: 0.0541\n",
      "Epoch 21/160\n",
      "6445/6428 [==============================] - 477s - loss: 0.1527 - val_loss: 0.0555\n",
      "Epoch 22/160\n",
      "6454/6428 [==============================] - 477s - loss: 0.1349 - val_loss: 0.0569\n",
      "Epoch 23/160\n",
      "6456/6428 [==============================] - 481s - loss: 0.1361 - val_loss: 0.0500\n",
      "Epoch 24/160\n",
      "6469/6428 [==============================] - 479s - loss: 0.1172 - val_loss: 0.0553\n",
      "Epoch 25/160\n",
      "6481/6428 [==============================] - 477s - loss: 0.1262 - val_loss: 0.0510\n",
      "Epoch 26/160\n",
      "6454/6428 [==============================] - 476s - loss: 0.1149 - val_loss: 0.0505\n",
      "Epoch 27/160\n",
      "6483/6428 [==============================] - 478s - loss: 0.1126 - val_loss: 0.0541\n",
      "Epoch 28/160\n",
      "6456/6428 [==============================] - 480s - loss: 0.0917 - val_loss: 0.0504\n",
      "Epoch 29/160\n",
      "6435/6428 [==============================] - 481s - loss: 0.0934 - val_loss: 0.0499\n",
      "Epoch 30/160\n",
      "6465/6428 [==============================] - 476s - loss: 0.0841 - val_loss: 0.0547\n",
      "Epoch 31/160\n",
      "6430/6428 [==============================] - 474s - loss: 0.0857 - val_loss: 0.0471\n",
      "Epoch 32/160\n",
      "6445/6428 [==============================] - 480s - loss: 0.0818 - val_loss: 0.0481\n",
      "Epoch 33/160\n",
      "6480/6428 [==============================] - 491s - loss: 0.0757 - val_loss: 0.0523\n",
      "Epoch 34/160\n",
      "6445/6428 [==============================] - 485s - loss: 0.0769 - val_loss: 0.0429\n",
      "Epoch 35/160\n",
      "6475/6428 [==============================] - 489s - loss: 0.0711 - val_loss: 0.0491\n",
      "Epoch 36/160\n",
      "6454/6428 [==============================] - 484s - loss: 0.0684 - val_loss: 0.0462\n",
      "Epoch 37/160\n",
      "6450/6428 [==============================] - 483s - loss: 0.0742 - val_loss: 0.0435\n",
      "Epoch 38/160\n",
      "6453/6428 [==============================] - 490s - loss: 0.0672 - val_loss: 0.0452\n",
      "Epoch 39/160\n",
      "6475/6428 [==============================] - 493s - loss: 0.0648 - val_loss: 0.0411\n",
      "Epoch 40/160\n",
      "6456/6428 [==============================] - 481s - loss: 0.0672 - val_loss: 0.0415\n",
      "Epoch 41/160\n",
      "6475/6428 [==============================] - 490s - loss: 0.0598 - val_loss: 0.0422\n",
      "Epoch 42/160\n",
      "6446/6428 [==============================] - 484s - loss: 0.0623 - val_loss: 0.0425\n",
      "Epoch 43/160\n",
      "6465/6428 [==============================] - 485s - loss: 0.0585 - val_loss: 0.0418\n",
      "Epoch 44/160\n",
      "5782/6428 [=========================>....] - ETA: 46s - loss: 0.0623"
     ]
    }
   ],
   "source": [
    "h, w, d = 160, 320, 3\n",
    "cropping_upper, cropping_bottom = 50, 20\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Lambda(lambda x: (x / 255.0), input_shape=(h, w, d)))\n",
    "model.add(Cropping2D(cropping=((cropping_upper,cropping_bottom), (0,0))))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Convolution2D(24, 5,5, subsample=(2,2), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#model.add(Convolution2D(36, 5,5, subsample=(2,2), activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "#model.add(Convolution2D(48, 5,5, subsample=(2,2), activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "#model.add(Convolution2D(64, 3,3, subsample=(1,1), activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "#model.add(Convolution2D(64, 3,3, subsample=(1,1), activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1164))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#model.add(Dense(50))\n",
    "#model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1))\n",
    "adam = Adam(lr=0.0002)\n",
    "\n",
    "model.compile(loss='mse', optimizer=adam)\n",
    "\n",
    "history_object = model.fit_generator(train_generator, samples_per_epoch=\n",
    "                                    len(train_samples), validation_data=\n",
    "                                    validation_generator, nb_val_samples=\n",
    "                                    len(validation_samples), nb_epoch=160,\n",
    "                                    verbose=1)\n",
    "\n",
    "model.save('model.h5')\n",
    "\n",
    "### print the keys contained in the history object \n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
