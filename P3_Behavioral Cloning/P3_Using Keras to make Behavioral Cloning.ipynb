{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from keras.layers import pooling\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Flatten, Dense, Lambda, Activation\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Cropping2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "with open('./data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "#         print(line[0])\n",
    "        lines.append(line)\n",
    "    lines = lines[1:]\n",
    "\n",
    "# path = './data/'\n",
    "# get_None_idx = []\n",
    "# for idx, line in enumerate(lines):\n",
    "#     line[1] = line[1][1:]\n",
    "#     line[2] = line[2][1:]\n",
    "#     if cv2.imread(path + line[0]) is None:\n",
    "#         get_None_idx.append(idx)\n",
    "    \n",
    "#     if cv2.imread(path + line[1]) is None:\n",
    "#         get_None_idx.append(idx)\n",
    "        \n",
    "#     if cv2.imread(path + line[2]) is None:\n",
    "#         get_None_idx.append(idx)\n",
    "    \n",
    "# images = []\n",
    "# measurments = []\n",
    "# for line in lines:\n",
    "#     # Create train_X\n",
    "#     # read in images from center, left and right cameras    \n",
    "#     image_center = cv2.imread(path + line[0]) # load the center_image\n",
    "#     image_left = cv2.imread(path + line[1]) # load the left_image\n",
    "#     image_right = cv2.imread(path + line[2]) # load the right_image\n",
    "    \n",
    "#     # append every image to images list\n",
    "#     images.extend((image_center, image_left, image_right)) \n",
    "    \n",
    "#     # Create train_Y\n",
    "#     steering_center = float(line[3])# steering measurment\n",
    "#     # create adjusted steering measurements for the side camera images\n",
    "#     correction = 0.2 # this is a parameter to tune\n",
    "#     steering_left = steering_center + correction\n",
    "#     steering_right = steering_center - correction\n",
    "    \n",
    "#     measurments.extend((steering_center, steering_left, steering_right))\n",
    "    \n",
    "# images = np.array(images)\n",
    "# measurments = np.array(measurments)\n",
    "\n",
    "# # Data augumentation: flip image in order to let it includes both clockwise and counter-clockwise images\n",
    "# flip_images = []\n",
    "# measurments_flipped = []\n",
    "# for image, measurement in zip(images, measurements):\n",
    "#     flip_images.append(np.fliplr(image))\n",
    "#     measurments_flipped.append(-measurement)\n",
    "# flip_images = np.array(flip_images)\n",
    "# measurments_flipped = np.array(measurments_flipped)\n",
    "\n",
    "# train_X = np.array(np.concatenate([images, flip_images], axis=0))\n",
    "# train_Y = np.array(np.concatenate([measurments, measurments_flipped], axis=0))\n",
    "\n",
    "# # train, validation split\n",
    "# train_samples, validation_samples = train_test_split(samples, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = []\n",
    "for ii in lines:\n",
    "    angle.append(float(ii[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4361"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_0 = 0\n",
    "for i in angle:\n",
    "    if i == 0.0:\n",
    "        count_0 += 1 \n",
    "count_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f26fe87160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histgram\n",
    "bins = np.arange(-0.5, 0.5, 0.01)\n",
    "\n",
    "plt.hist(angle, bins=bins, alpha=0.3, label='angles')\n",
    "# plt.hist(np.concatenate([L2_label_1_full,L2_label_1_test_full],axis=0), bins=bins, alpha=0.3, label='label_1')\n",
    "# plt.hist(y_test, bins=bins, alpha=0.3, label='y_test')\n",
    "plt.title('Distribution of different steering angles')\n",
    "plt.ylabel('numbers')\n",
    "plt.xlabel('Angles')\n",
    "plt.legend(loc='upper right')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IMG/center_2016_12_01_13_30_48_287.jpg'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cut angle zero data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick up the data with zero steer angles\n",
    "zero_angle_idx = []\n",
    "non_zero_angle_idx = []\n",
    "for idx, ag in enumerate(angle):\n",
    "    if ag == 0.0:\n",
    "        zero_angle_idx.append(idx)\n",
    "    else:\n",
    "        non_zero_angle_idx.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick up the center images path that with zero angles\n",
    "center_with_zero_list = []\n",
    "for zero_idx in zero_angle_idx:\n",
    "    center_with_zero_list.append([lines[zero_idx][0], 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick up the center and side images path that with non-zero angles\n",
    "center_with_non_zero_list = []\n",
    "for non_zero_idx in non_zero_angle_idx:\n",
    "    center_with_non_zero_list.append([lines[non_zero_idx][0], lines[non_zero_idx][1], lines[non_zero_idx][2], lines[non_zero_idx][3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [cv2.flip](https://docs.opencv.org/2.4/modules/core/doc/operations_on_arrays.html?highlight=cv2.flip#cv2.flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(samples, batch_size=50, correc=0.2):\n",
    "    \n",
    "    '''\n",
    "    samples: \n",
    "    correc: parameter to control the deviation of left and right steering angles\n",
    "    batch_size: you know what is that\n",
    "    '''\n",
    "    \n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for start_point in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[start_point : start_point + batch_size]\n",
    "            \n",
    "            images = []\n",
    "            angles = []\n",
    "            for sample in batch_samples:\n",
    "                path = './data/'\n",
    "            # Create train_X\n",
    "            # read in images from center, left and right cameras    \n",
    "                image_center = cv2.imread(path + sample[0]) # load the center_image\n",
    "                image_left = cv2.imread(path + sample[1]) # load the left_image\n",
    "                image_right = cv2.imread(path + sample[2]) # load the right_image\n",
    "    \n",
    "            # append every image to images list\n",
    "                images.extend((image_center, image_left, image_right)) \n",
    "    \n",
    "            # Create train_Y\n",
    "                steering_center = float(sample[3])# steering measurment\n",
    "            # create adjusted steering measurements for the side camera images\n",
    "                correction = correc # this is a parameter to tune\n",
    "                steering_left = steering_center + correction\n",
    "                steering_right = steering_center - correction\n",
    "    \n",
    "                angles.extend((steering_center, steering_left, steering_right))\n",
    "    \n",
    "            images = np.array(images)\n",
    "            angles = np.array(angles)\n",
    "#             print(images.shape)\n",
    "            # Data augumentation: flip image in order to let it includes both clockwise and counter-clockwise images\n",
    "            images_flipped = []\n",
    "            angles_flipped = []\n",
    "            for image, angle in zip(images, angles):\n",
    "                images_flipped.append(cv2.flip(image, 1))\n",
    "                angles_flipped.append(angle*-1.0)\n",
    "            images_flipped = np.array(images_flipped)\n",
    "            angles_flipped = np.array(angles_flipped)\n",
    "#             print(images[0].shape)\n",
    "            train_X = np.array(np.concatenate([images, images_flipped], axis=0))\n",
    "#             print(train_X.shape)\n",
    "            train_Y = np.array(np.concatenate([angles, angles_flipped], axis=0))\n",
    "            train_X, train_Y = sklearn.utils.shuffle(train_X, train_Y)\n",
    "        \n",
    "            yield train_X, train_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To build the Network Archtecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, validation split\n",
    "# actually we split the path but not total data, the data will be read by generator\n",
    "train_samples, validation_samples = train_test_split(lines, test_size=0.2)\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "correct = 0.2\n",
    "batch_size = 40\n",
    "\n",
    "train_generator = data_generator(train_samples, batch_size=batch_size, correc=correct)\n",
    "validation_generator = data_generator(validation_samples, batch_size=batch_size, correc=correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "6240/6428 [============================>.] - ETA: 5s - loss: 6.1300 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\keras\\engine\\training.py:1569: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6480/6428 [==============================] - 202s - loss: 6.0946 - val_loss: 0.0491\n",
      "Epoch 2/30\n",
      "6480/6428 [==============================] - 199s - loss: 3.5366 - val_loss: 0.1151\n",
      "Epoch 3/30\n",
      "6648/6428 [===============================] - 204s - loss: 2.6921 - val_loss: 0.2074\n",
      "Epoch 4/30\n",
      " 240/6428 [>.............................] - ETA: 174s - loss: 2.7386"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-7f1effc1e4ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     59\u001b[0m                                     \u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_val_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m                                     \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                     verbose=1)\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    933\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    936\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m     def evaluate_generator(self, generator, val_samples,\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[0;32m   1551\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   1552\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1553\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   1554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1555\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1314\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1316\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1317\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1898\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1899\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m-> 1900\u001b[1;33m                               feed_dict=feed_dict)\n\u001b[0m\u001b[0;32m   1901\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1902\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 766\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    767\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    962\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 964\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    965\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1014\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1015\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1019\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1022\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1003\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "h, w, d = 160, 320, 3\n",
    "cropping_upper, cropping_bottom = 50, 20\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Lambda(lambda x: (x / 255.0), input_shape=(h, w, d)))\n",
    "model.add(Cropping2D(cropping=((cropping_upper,cropping_bottom), (0,0))))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Convolution2D(24, 5,5, subsample=(2,2), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Convolution2D(36, 5,5, subsample=(2,2), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#model.add(Convolution2D(48, 5,5, subsample=(2,2), activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "#model.add(Convolution2D(64, 3,3, subsample=(1,1), activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "#model.add(Convolution2D(64, 3,3, subsample=(1,1), activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1164))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#model.add(Dense(50))\n",
    "#model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1))\n",
    "adam = Adam(lr=0.0003)\n",
    "\n",
    "model.compile(loss='mse', optimizer=adam)\n",
    "\n",
    "history_object = model.fit_generator(train_generator, samples_per_epoch=\n",
    "                                    len(train_samples), validation_data=\n",
    "                                    validation_generator, nb_val_samples=\n",
    "                                    len(validation_samples), nb_epoch=30,\n",
    "                                    verbose=1)\n",
    "\n",
    "model.save('model.h5')\n",
    "\n",
    "### print the keys contained in the history object \n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
