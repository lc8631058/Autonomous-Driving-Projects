{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from keras.layers import pooling\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Flatten, Dense, Lambda, Activation\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Cropping2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "with open('./data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "#         print(line[0])\n",
    "        lines.append(line)\n",
    "    lines = lines[1:]\n",
    "\n",
    "# path = './data/'\n",
    "# get_None_idx = []\n",
    "# for idx, line in enumerate(lines):\n",
    "#     line[1] = line[1][1:]\n",
    "#     line[2] = line[2][1:]\n",
    "#     if cv2.imread(path + line[0]) is None:\n",
    "#         get_None_idx.append(idx)\n",
    "    \n",
    "#     if cv2.imread(path + line[1]) is None:\n",
    "#         get_None_idx.append(idx)\n",
    "        \n",
    "#     if cv2.imread(path + line[2]) is None:\n",
    "#         get_None_idx.append(idx)\n",
    "    \n",
    "# images = []\n",
    "# measurments = []\n",
    "# for line in lines:\n",
    "#     # Create train_X\n",
    "#     # read in images from center, left and right cameras    \n",
    "#     image_center = cv2.imread(path + line[0]) # load the center_image\n",
    "#     image_left = cv2.imread(path + line[1]) # load the left_image\n",
    "#     image_right = cv2.imread(path + line[2]) # load the right_image\n",
    "    \n",
    "#     # append every image to images list\n",
    "#     images.extend((image_center, image_left, image_right)) \n",
    "    \n",
    "#     # Create train_Y\n",
    "#     steering_center = float(line[3])# steering measurment\n",
    "#     # create adjusted steering measurements for the side camera images\n",
    "#     correction = 0.2 # this is a parameter to tune\n",
    "#     steering_left = steering_center + correction\n",
    "#     steering_right = steering_center - correction\n",
    "    \n",
    "#     measurments.extend((steering_center, steering_left, steering_right))\n",
    "    \n",
    "# images = np.array(images)\n",
    "# measurments = np.array(measurments)\n",
    "\n",
    "# # Data augumentation: flip image in order to let it includes both clockwise and counter-clockwise images\n",
    "# flip_images = []\n",
    "# measurments_flipped = []\n",
    "# for image, measurement in zip(images, measurements):\n",
    "#     flip_images.append(np.fliplr(image))\n",
    "#     measurments_flipped.append(-measurement)\n",
    "# flip_images = np.array(flip_images)\n",
    "# measurments_flipped = np.array(measurments_flipped)\n",
    "\n",
    "# train_X = np.array(np.concatenate([images, flip_images], axis=0))\n",
    "# train_Y = np.array(np.concatenate([measurments, measurments_flipped], axis=0))\n",
    "\n",
    "# # train, validation split\n",
    "# train_samples, validation_samples = train_test_split(samples, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# angle = []\n",
    "for ii in lines:\n",
    "    angle.append(float(ii[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4361"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_0 = 0\n",
    "for i in angle:\n",
    "    if i == 0.0:\n",
    "        count_0 += 1 \n",
    "count_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1328844a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histgram\n",
    "bins = np.arange(-0.5, 0.5, 0.01)\n",
    "\n",
    "plt.hist(angle, bins=bins, alpha=0.3, label='angles')\n",
    "# plt.hist(np.concatenate([L2_label_1_full,L2_label_1_test_full],axis=0), bins=bins, alpha=0.3, label='label_1')\n",
    "# plt.hist(y_test, bins=bins, alpha=0.3, label='y_test')\n",
    "plt.title('Distribution of different steering angles')\n",
    "plt.ylabel('numbers')\n",
    "plt.xlabel('Angles')\n",
    "plt.legend(loc='upper right')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "# center_with_zero_list = []\n",
    "# for zero_idx in train_zero_angle_idx:\n",
    "#     center_with_zero_list.append([train_samples[zero_idx][0], 0.0, 'C'])\n",
    "    \n",
    "#     # pick up the center and side images path that with non-zero angles\n",
    "# center_with_non_zero_list = []\n",
    "# left_with_non_zero_list = []\n",
    "# right_with_non_zero_list = []\n",
    "\n",
    "# for non_zero_idx in train_non_zero_angle_idx:\n",
    "#         # create adjusted steering measurements for the side camera images\n",
    "#     center_with_non_zero_list.append([train_samples[non_zero_idx][0], train_samples[non_zero_idx][3], 'C'])\n",
    "#     left_with_non_zero_list.append([train_samples[non_zero_idx][1], float(train_samples[non_zero_idx][3]) + 0.2, 'L'])\n",
    "#     right_with_non_zero_list.append([train_samples[non_zero_idx][2], float(train_samples[non_zero_idx][3]) - 0.2, 'R'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None None None None None None None None None None None None None None None\n",
      " None None None None None None None None None]\n",
      "(16, 160, 320, 3) (24,) (24,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-430-72ba9da1f9b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mangles_flipped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mangles_flipped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_center_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_side_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages_flipped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mtrain_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_center_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_side_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages_flipped\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mtrain_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_center_angle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_side_angle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangles_flipped\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"
     ]
    }
   ],
   "source": [
    "center_with_zero_list = []\n",
    "for zero_idx in zero_angle_idx:\n",
    "    center_with_zero_list.append([lines[zero_idx][0], 0.0, 'C'])\n",
    "    \n",
    "    # pick up the center and side images path that with non-zero angles\n",
    "center_with_non_zero_list = []\n",
    "left_with_non_zero_list = []\n",
    "right_with_non_zero_list = []\n",
    "\n",
    "for non_zero_idx in non_zero_angle_idx:\n",
    "        # create adjusted steering measurements for the side camera images\n",
    "    center_with_non_zero_list.append([lines[non_zero_idx][0], lines[non_zero_idx][3], 'C'])\n",
    "    left_with_non_zero_list.append([lines[non_zero_idx][1], float(lines[non_zero_idx][3]) + 0.2, 'L'])\n",
    "    right_with_non_zero_list.append([lines[non_zero_idx][2], float(lines[non_zero_idx][3]) - 0.2, 'R'])\n",
    "    \n",
    "samples = np.concatenate([np.array(center_with_zero_list), np.array(center_with_non_zero_list),\n",
    "                              np.array(left_with_non_zero_list), np.array(right_with_non_zero_list)], axis=0)\n",
    "    \n",
    "num_samples = len(samples)\n",
    "while 1: # Loop forever so the generator never terminates\n",
    "    samples = shuffle(samples)\n",
    "    \n",
    "    for start_point in range(0, num_samples, batch_size):\n",
    "        batch_samples = samples[start_point : start_point + batch_size]\n",
    "            \n",
    "        image_center_list = []\n",
    "        image_center_angle = []\n",
    "        image_side_list = []\n",
    "        image_side_angle = []\n",
    "            \n",
    "        for sample in batch_samples:\n",
    "            path = './data/'\n",
    "            # Create train_X\n",
    "            # read in images from center, left and right cameras    \n",
    "            if sample[2] == 'C':\n",
    "                image_center = cv2.imread(path + sample[0]) # load the center_image\n",
    "                image_center_list.append(image_center) \n",
    "                image_center_angle.append(float(sample[1]))\n",
    "                    \n",
    "            if sample[2] == 'L' or sample[2] == 'R':\n",
    "                image_side = cv2.imread(path + sample[0]) # load the left_image\n",
    "                image_side_list.append(image_side) \n",
    "                image_side_angle.append(float(sample[1]))\n",
    "\n",
    "        image_center_list = np.array(image_center_list)\n",
    "        image_center_angle = np.array(image_center_angle)\n",
    "        image_side_list = np.array(image_side_list)\n",
    "        image_side_angle = np.array(image_side_angle)\n",
    "#         print(image_side_list)\n",
    "            # Data augumentation: flip image in order to let it includes both clockwise and counter-clockwise images\n",
    "            \n",
    "            # only flip side-images:\n",
    "        if len(image_side_list) != 0:\n",
    "            images_flipped = []\n",
    "            angles_flipped = []\n",
    "            for image, angle in zip(image_side_list, image_side_angle):\n",
    "                images_flipped.append(cv2.flip(image, 1))\n",
    "                angles_flipped.append(angle*-1.0)\n",
    "            images_flipped = np.array(images_flipped)\n",
    "            angles_flipped = np.array(angles_flipped)\n",
    "            \n",
    "#         print(image_center_list.shape, image_side_list.shape, images_flipped.shape)\n",
    "    \n",
    "        train_X = np.array(np.concatenate([image_center_list, image_side_list, images_flipped], axis=0))\n",
    "        train_Y = np.array(np.concatenate([image_center_angle, image_side_angle, angles_flipped], axis=0))\n",
    "        train_X, train_Y = sklearn.utils.shuffle(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [cv2.flip](https://docs.opencv.org/2.4/modules/core/doc/operations_on_arrays.html?highlight=cv2.flip#cv2.flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(lines, zero_angle_idx, non_zero_angle_idx, batch_size=50, correc=0.3):\n",
    "    \n",
    "    '''\n",
    "    samples: \n",
    "    correc: parameter to control the deviation of left and right steering angles\n",
    "    batch_size: you know what is that\n",
    "    '''\n",
    "    # pick up the center images path that with zero angles\n",
    "    center_with_zero_list = []\n",
    "    for zero_idx in zero_angle_idx:\n",
    "        center_with_zero_list.append([lines[zero_idx][0], 0.0, 'C'])\n",
    "    \n",
    "    # pick up the center and side images path that with non-zero angles\n",
    "    center_with_non_zero_list = []\n",
    "    left_with_non_zero_list = []\n",
    "    right_with_non_zero_list = []\n",
    "\n",
    "    for non_zero_idx in non_zero_angle_idx:\n",
    "        # create adjusted steering measurements for the side camera images\n",
    "        center_with_non_zero_list.append([lines[non_zero_idx][0], lines[non_zero_idx][3], 'C'])\n",
    "        left_with_non_zero_list.append([lines[non_zero_idx][1], float(lines[non_zero_idx][3]) + correc, 'L'])\n",
    "        right_with_non_zero_list.append([lines[non_zero_idx][2], float(lines[non_zero_idx][3]) - correc, 'R'])\n",
    "    \n",
    "    samples = np.concatenate([np.array(center_with_zero_list), np.array(center_with_non_zero_list),\n",
    "                              np.array(left_with_non_zero_list), np.array(right_with_non_zero_list)], axis=0)\n",
    "    \n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        samples = shuffle(samples)\n",
    "    \n",
    "        for start_point in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[start_point : start_point + batch_size]\n",
    "            \n",
    "            image_center_list = []\n",
    "            image_center_angle = []\n",
    "            image_side_list = []\n",
    "            image_side_angle = []\n",
    "            \n",
    "            for sample in batch_samples:\n",
    "                path = './data/'\n",
    "            # Create train_X\n",
    "            # read in images from center, left and right cameras    \n",
    "                if sample[2] == 'C':\n",
    "                    image_center = cv2.imread(path + sample[0]) # load the center_image\n",
    "                    image_center_list.append(image_center) \n",
    "                    image_center_angle.append(float(sample[1]))\n",
    "                    \n",
    "                if sample[2] == 'L' or sample[2] == 'R':\n",
    "                    image_side = cv2.imread(path + sample[0]) # load the left_image\n",
    "                    image_side_list.append(image_side) \n",
    "                    image_side_angle.append(float(sample[1]))\n",
    "\n",
    "            image_center_list = np.array(image_center_list)\n",
    "            image_center_angle = np.array(image_center_angle)\n",
    "            image_side_list = np.array(image_side_list)\n",
    "            image_side_angle = np.array(image_side_angle)\n",
    "\n",
    "            # Data augumentation: flip image in order to let it includes both clockwise and counter-clockwise images\n",
    "            \n",
    "            # only flip side-images:\n",
    "            images_flipped = []\n",
    "            angles_flipped = []\n",
    "            for image, angle in zip(image_side_list, image_side_angle):\n",
    "                images_flipped.append(cv2.flip(image, 1))\n",
    "                angles_flipped.append(angle*-1.0)\n",
    "            images_flipped = np.array(images_flipped)\n",
    "            angles_flipped = np.array(angles_flipped)\n",
    "            \n",
    "            train_X = np.array(np.concatenate([image_center_list, image_side_list, images_flipped], axis=0))\n",
    "            train_Y = np.array(np.concatenate([image_center_angle, image_side_angle, angles_flipped], axis=0))\n",
    "            train_X, train_Y = sklearn.utils.shuffle(train_X, train_Y)\n",
    "        \n",
    "            yield train_X, train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-432-6be8f38d3987>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "next(train_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To build the Network Archtecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index(lines):\n",
    "    '''\n",
    "    find out the index of the lines which have zero angles and non-zero angles\n",
    "    '''\n",
    "    zero_angle_idx = []\n",
    "    non_zero_angle_idx = []\n",
    "    for idx, line in enumerate(lines):\n",
    "        if line[3] == '0':\n",
    "            zero_angle_idx.append(idx)\n",
    "        else:\n",
    "            non_zero_angle_idx.append(idx)\n",
    "            \n",
    "    return zero_angle_idx, non_zero_angle_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, validation split\n",
    "# actually we split the path but not total data, the data will be read by generator\n",
    "train_samples, validation_samples = train_test_split(lines, test_size=0.2)\n",
    "\n",
    "# cut angle zero data, find out the index of zero-angle data and non-zero-angle data\n",
    "# pick up the data with zero steer angles\n",
    "train_zero_angle_idx, train_non_zero_angle_idx = find_index(train_samples)\n",
    "valid_zero_angle_idx, valid_non_zero_angle_idx = find_index(validation_samples)\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "correct = 0.25\n",
    "batch_size = 40\n",
    "\n",
    "train_generator = data_generator(train_samples, train_zero_angle_idx, train_non_zero_angle_idx, batch_size=batch_size, correc=correct)\n",
    "validation_generator = data_generator(validation_samples, valid_zero_angle_idx, valid_non_zero_angle_idx, batch_size=batch_size, correc=correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 360/6428 [>.............................] - ETA: 1285s - loss: 9.0728"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-441-4659549a6ec3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m                                     \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_val_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                                     \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                     verbose=1)\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/carnd-term1/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    933\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m     def evaluate_generator(self, generator, val_samples,\n",
      "\u001b[0;32m~/anaconda/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1551\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1552\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1314\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/carnd-term1/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1898\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1899\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 1900\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   1901\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "h, w, d = 160, 320, 3\n",
    "cropping_upper, cropping_bottom = 50, 20\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Lambda(lambda x: (x / 255.0), input_shape=(h, w, d)))\n",
    "model.add(Cropping2D(cropping=((cropping_upper,cropping_bottom), (0,0))))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Convolution2D(24, 5,5, subsample=(2,2), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Convolution2D(36, 5,5, subsample=(2,2), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#model.add(Convolution2D(48, 5,5, subsample=(2,2), activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "#model.add(Convolution2D(64, 3,3, subsample=(1,1), activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "#model.add(Convolution2D(64, 3,3, subsample=(1,1), activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1164))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#model.add(Dense(50))\n",
    "#model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1))\n",
    "adam = Adam(lr=0.0003)\n",
    "\n",
    "model.compile(loss='mse', optimizer=adam)\n",
    "\n",
    "history_object = model.fit_generator(train_generator, samples_per_epoch=\n",
    "                                    len(train_samples), validation_data=\n",
    "                                    validation_generator, nb_val_samples=\n",
    "                                    len(validation_samples), nb_epoch=3,\n",
    "                                    verbose=1)\n",
    "\n",
    "model.save('model.h5')\n",
    "\n",
    "### print the keys contained in the history object \n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
